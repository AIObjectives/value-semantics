{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Setup"
      ],
      "metadata": {
        "id": "p8gEKF2B6J63"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PR-IgdVrwQDW",
        "outputId": "bae6f162-17ed-444b-d7b8-450b52ffc14e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n"
          ]
        }
      ],
      "source": [
        "#install packages not native to colab\n",
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#import packages\n",
        "import os, sys, math, random\n",
        "import requests, json\n",
        "import re, io, ast\n",
        "import openai\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import permutations\n",
        "from google.colab import drive, files, data_table"
      ],
      "metadata": {
        "id": "Z7xIRlEi4ovq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set up paths for local modules and data sources\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "sys.path.append('/content/drive/Shareddrives/MoralLearning/GPT_v1/')\n",
        "stim_path = \"/content/drive/Shareddrives/MoralLearning/Stimuli/\"\n",
        "data_path = '/content/drive/Shareddrives/MoralLearning/GPT_v1/Results/'\n",
        "#import local modules\n",
        "from GPT import promptGPT2, getEmbeddings\n",
        "from utilities import *"
      ],
      "metadata": {
        "id": "KNtypcL84r1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#set environment variable with API key\n",
        "%env OPENAI_API_KEY = Bearer [add key here]\n",
        "# os.getenv(\"OPENAI_API_KEY\")\n",
        "openai.api_key = '[add key here]'"
      ],
      "metadata": {
        "id": "_1ADE_Ju4vUY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Embeddings"
      ],
      "metadata": {
        "id": "44tS5vRD6Ocu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def return_embeddings_diff(attributes_a, attributes_b):\n",
        "  '''\n",
        "  Pass two sets of attributes and get all vector differences of all a-b combinations\n",
        "  '''\n",
        "  emb_high = pd.DataFrame()\n",
        "  emb_low = pd.DataFrame()\n",
        "\n",
        "  #loop through each attribute set and save the embeddings in two dataframes\n",
        "  for a in range(len(attributes_a)):\n",
        "    #get embedding of the high, low, and compute difference\n",
        "    this_emb = getEmbeddings(attributes_a[a])\n",
        "    emb_high.insert(loc=0,column=a,value=this_emb[\"data\"][0][\"embedding\"])\n",
        "\n",
        "  for b in range(len(attributes_b)):\n",
        "    #get embedding of the high, low, and compute difference\n",
        "    this_emb = getEmbeddings(attributes_b[b])\n",
        "    emb_low.insert(loc=0,column=b,value=this_emb[\"data\"][0][\"embedding\"])\n",
        "\n",
        "  #get all differences\n",
        "  vector_diff = pd.DataFrame()\n",
        "\n",
        "  for a in range(len(attributes_a)):\n",
        "    for b in range(len(attributes_b)):\n",
        "      this_col = str(a)+'_'+str(b)\n",
        "      vector_diff.insert(loc=0,column = this_col, value = emb_high[a] - emb_low[b])\n",
        "\n",
        "  return(vector_diff.mean(axis=1))\n",
        "\n",
        "\n",
        "def return_list_embeddings(alist):\n",
        "  '''\n",
        "  get embeddings for a list of items\n",
        "  '''\n",
        "  n_df = pd.DataFrame()\n",
        "  for i in alist:\n",
        "    this_em = getEmbeddings(i)[\"data\"][0][\"embedding\"]\n",
        "    n_df.insert(loc=0,column = i,value = this_em, allow_duplicates = True)\n",
        "\n",
        "  return (n_df)\n",
        "\n",
        "\n",
        "def get_projections(stim_list, moral_v, hedonic_v, movement_v):\n",
        "  '''\n",
        "  get projections for list of items\n",
        "  '''\n",
        "  #construct dataframe to save items\n",
        "  projection_df = pd.DataFrame(index=stim_list,columns = ['moral_v','hedonic_v','movement_v'],data=0)\n",
        "\n",
        "  #loop through items to get embeddings in moral, hedonic, and movement vector directions\n",
        "\n",
        "  for a in stim_list:\n",
        "    this_em = getEmbeddings(a)[\"data\"][0][\"embedding\"]\n",
        "    projection_moral = np.inner(np.array(this_em),np.array(moral_v))\n",
        "    projection_hedonic = np.inner(np.array(this_em),np.array(hedonic_v))\n",
        "    projection_movement = np.inner(np.array(this_em),np.array(movement_v))\n",
        "    projection_df.loc[a,\"moral_v\"] = projection_moral\n",
        "    projection_df.loc[a,\"hedonic_v\"] = projection_hedonic\n",
        "    projection_df.loc[a,\"movement_v\"] = projection_movement\n",
        "\n",
        "  return projection_df"
      ],
      "metadata": {
        "id": "VOjHhww-410g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get moral direction in GPT embeddings\n",
        "attributes_morality_high = ['morally virtuous','ethical', 'high moral value']\n",
        "attributes_morality_low = ['morally wrong','unethical', 'low moral value']\n",
        "moral_v = return_embeddings_diff(attributes_morality_high,attributes_morality_low)\n",
        "moral_v.to_csv(data_path+'moral_direction_embeddings.csv')\n",
        "\n",
        "# get hedonic direction in GPT embeddings\n",
        "attributes_hedonic_high = ['personally rewarding','pleasurable for me', 'high hedonic value for me']\n",
        "attributes_hedonic_low = ['personally costly','unpleasurable for me', 'low hedonic value for me']\n",
        "hedonic_v = return_embeddings_diff(attributes_hedonic_high,attributes_hedonic_low)\n",
        "hedonic_v.to_csv(data_path+'hedonic_direction_embeddings.csv')\n",
        "\n",
        "# get physicality direction in GPT embeddings\n",
        "attributes_movement_high = ['physical','bodily action', 'high movement']\n",
        "attributes_movement_low = ['mental','minimally active', 'low movement']\n",
        "movement_v = return_embeddings_diff(attributes_movement_high,attributes_movement_low)\n",
        "movement_v.to_csv(data_path+'movement_direction_embeddings.csv')"
      ],
      "metadata": {
        "id": "c3RGW10_5CWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read in stimuli to project\n",
        "action_data = pd.read_csv(stim_path+\"action_neurips.csv\",header=None)\n",
        "action_list_all = action_data[0].tolist()\n",
        "\n",
        "# split into three batches to match the prompting method\n",
        "action_list_1 = action_list_all[0:18]\n",
        "action_list_2 = action_list_all[18:36]\n",
        "action_list_3 = action_list_all[36:]"
      ],
      "metadata": {
        "id": "AA-eZvG25KbI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get projections of stimuli onto each vector direction\n",
        "\n",
        "#batch 1\n",
        "projections_1 = get_projections(action_list_1, moral_v, hedonic_v, movement_v)\n",
        "projections_1.to_csv(data_path + \"vector_projections_batch1.csv\")\n",
        "\n",
        "#batch 2\n",
        "projections_2 = get_projections(action_list_2, moral_v, hedonic_v, movement_v)\n",
        "projections_2.to_csv(data_path + \"vector_projections_batch2.csv\")\n",
        "\n",
        "#batch 3\n",
        "projections_3 = get_projections(action_list_3, moral_v, hedonic_v, movement_v)\n",
        "projections_3.to_csv(data_path + \"vector_projections_batch3.csv\")"
      ],
      "metadata": {
        "id": "MFRJQeUw5NS3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Report correlation among attribute embeddings\n",
        "print('Correlation between moral and hedonic embedding is '+ str(correlate(moral_v,hedonic_v)[0,1]))\n",
        "print('Correlation between moral and movement embedding is '+ str(correlate(moral_v,movement_v)[0,1]))\n",
        "print('Correlation between hedonic and hedonic embedding is '+ str(correlate(hedonic_v,movement_v)[0,1]))"
      ],
      "metadata": {
        "id": "cKXsQajo5XcK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Report correlation among items in terms of their projections\n",
        "\n",
        "#for this, concatenate all three batches\n",
        "projection_df = pd.concat([projections_1,projections_2,projections_3],axis=0)\n",
        "print(projection_df.shape)\n",
        "print('Moral and hedonic item correlation is '+str(correlate(projection_df[\"moral_v\"],projection_df[\"hedonic_v\"])[0,1]))\n",
        "print('Moral and movement item correlation is '+str(correlate(projection_df[\"moral_v\"],projection_df[\"movement_v\"])[0,1]))\n",
        "print('Hedonic and movement item correlation is '+str(correlate(projection_df[\"hedonic_v\"],projection_df[\"movement_v\"])[0,1]))"
      ],
      "metadata": {
        "id": "iLo7YZfz5bVF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlations among prompted item distances\n",
        "\n",
        "#load results with sort & rate prompting in the three batches\n",
        "ratings_1=pd.read_csv(data_path +'neurips_actions_set1.csv',index_col=0)\n",
        "ratings_2=pd.read_csv(data_path +'neurips_actions_set2.csv',index_col=0)\n",
        "ratings_3=pd.read_csv(data_path +'neurips_actions_set3.csv',index_col=0)\n",
        "\n",
        "# correlate the ratings within set\n",
        "c1= correlate(ratings_1[\"rescored_moral\"],ratings_1[\"rescored_hedonic\"])[0,1]\n",
        "c2 = correlate(ratings_2[\"rescored_moral\"],ratings_2[\"rescored_hedonic\"])[0,1]\n",
        "c3 = correlate(ratings_3[\"rescored_moral\"],ratings_3[\"rescored_hedonic\"])[0,1]\n",
        "\n",
        "print('moral - hedonic item correlation with sort-rated distances is '+str(np.mean([c1,c2,c3])))"
      ],
      "metadata": {
        "id": "WTbpu5xO5iaK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation across embedding and prompted distances\n",
        "\n",
        "#moral\n",
        "#batch 1\n",
        "#ensure the items match across the sets\n",
        "items_exist = ratings_1[\"item\"].to_list()\n",
        "projections_match = projections_1.loc[items_exist]\n",
        "c1=correlate(ratings_1[\"rescored_moral\"],projections_match[\"moral_v\"])[0,1]\n",
        "\n",
        "#batch 2\n",
        "#ensure the items match across the sets\n",
        "items_exist = ratings_2[\"item\"].to_list()\n",
        "projections_match = projections_2.loc[items_exist]\n",
        "c2=correlate(ratings_2[\"rescored_moral\"],projections_match[\"moral_v\"])[0,1]\n",
        "\n",
        "#batch 3\n",
        "#ensure the items match across the sets\n",
        "items_exist = ratings_3[\"item\"].to_list()\n",
        "projections_match = projections_3.loc[items_exist]\n",
        "c3=correlate(ratings_3[\"rescored_moral\"],projections_match[\"moral_v\"])[0,1]\n",
        "\n",
        "print('Correlation on morality values between embeddings and prompted distances '+ str(np.mean([c1,c2,c3])))\n",
        "\n",
        "#hedonic\n",
        "#batch 1\n",
        "#ensure the items match across the sets\n",
        "items_exist = ratings_1[\"item\"].to_list()\n",
        "projections_match = projections_1.loc[items_exist]\n",
        "c4=correlate(ratings_1[\"rescored_hedonic\"],projections_match[\"hedonic_v\"])[0,1]\n",
        "\n",
        "#batch 2\n",
        "#ensure the items match across the sets\n",
        "items_exist = ratings_2[\"item\"].to_list()\n",
        "projections_match = projections_2.loc[items_exist]\n",
        "c5=correlate(ratings_2[\"rescored_hedonic\"],projections_match[\"hedonic_v\"])[0,1]\n",
        "\n",
        "#batch 3\n",
        "#ensure the items match across the sets\n",
        "items_exist = ratings_3[\"item\"].to_list()\n",
        "projections_match = projections_3.loc[items_exist]\n",
        "c6=correlate(ratings_3[\"rescored_hedonic\"],projections_match[\"hedonic_v\"])[0,1]\n",
        "\n",
        "print('Correlation on morality values between embeddings and prompted distances '+ str(np.mean([c4,c5,c6])))"
      ],
      "metadata": {
        "id": "dGnZLwoO5n_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot batch 1\n",
        "# sort proections by morality before plotting\n",
        "projections_1 = projections_1.sort_values('moral_v', ascending=False)\n",
        "projections_1"
      ],
      "metadata": {
        "id": "FmOt0AhT5slQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot moral v hedonic\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "cmap = plt.get_cmap(\"tab20\")\n",
        "\n",
        "plot_i = 1\n",
        "for i in range(len(projection_df)):\n",
        "    x = projection_df['hedonic_v'].iloc[i]\n",
        "    y = projection_df['moral_v'].iloc[i]\n",
        "    colors = cmap(i/len(projection_df))\n",
        "    l = str(plot_i) + '. ' + projection_df.index[i].lstrip('[').rstrip(']')\n",
        "    ax.scatter([x],[y], label=l)\n",
        "    ax.annotate(plot_i, (projection_df['hedonic_v'][i]+.0005, projection_df['moral_v'][i]-.0001))\n",
        "    plot_i += 1\n",
        "\n",
        "ax.set_xlabel('Hedonic')\n",
        "ax.set_ylabel('Moral')\n",
        "ax.legend()"
      ],
      "metadata": {
        "id": "LeVlXm5B5wA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot moral v movement\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "cmap = plt.get_cmap(\"tab20\")\n",
        "\n",
        "# Plot each item\n",
        "plot_i = 1\n",
        "for i in range(len(projection_df)):\n",
        "    x = projection_df['movement_v'].iloc[i]\n",
        "    y = projection_df['moral_v'].iloc[i]\n",
        "    colors = cmap(i/len(projection_df))\n",
        "    l = str(plot_i) + '. ' + projection_df.index[i].lstrip('[').rstrip(']')\n",
        "    ax.scatter([x],[y], label=l)\n",
        "    ax.annotate(plot_i, (projection_df['movement_v'][i]+.0005, projection_df['moral_v'][i]-.0001))\n",
        "    plot_i += 1\n",
        "\n",
        "ax.set_xlabel('Movement')\n",
        "ax.set_ylabel('Moral')\n",
        "ax.legend()"
      ],
      "metadata": {
        "id": "yCk-ftQj5zad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GPT prompt ranking"
      ],
      "metadata": {
        "id": "_6F_jsos84sK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompts\n",
        "def prompt_sort(action_list, dimension):\n",
        "\n",
        "  #randomize the order of the list\n",
        "  random.shuffle(action_list)\n",
        "\n",
        "  #turn list into formatted string\n",
        "  action_string = (', ').join(action_list)\n",
        "\n",
        "  # Switch by sorting dimension\n",
        "  if dimension == 'moral':\n",
        "    prompt = f'I will sort these actions in terms of their moral value.\\\n",
        "    I am sorting only on morality according to how morally wrong each action is,\\\n",
        "    starting with the most morally wrong and ending with the most morally virtuous.\\\n",
        "    I will format the list as a python list of strings. Here is an example.\\\n",
        "    Sort these actions: walk a dog, rob a bank, rescue a cat, steal food. \\\n",
        "    Response: [\"rob a bank\", \"steal food\", \"walk a dog\", \"rescue a cat\"]\\\n",
        "    Sort these actions: {action_string}.'\n",
        "\n",
        "  elif dimension == 'hedonic':\n",
        "    prompt = f'I will sort these actions in terms of how good and rewarding they are for myself.\\\n",
        "    I am sorting only on how good this action is for me,\\\n",
        "    starting with the most bad and least rewarding, and ending with the most good and rewarding.\\\n",
        "    I will format the list as a python list of strings. Here is an example.\\\n",
        "    Sort these actions: miss the bus, win a sweepstakes, eat a meal, lose my wallet.\\\n",
        "    Response: [\"lose my wallet\", \"miss the bus\", \"eat a meal\", \"win a sweepstakes\"]\\\n",
        "    Sort these actions: {action_string}.'\n",
        "\n",
        "  elif dimension == 'action':\n",
        "    prompt = f'I will sort these actions in terms of how much they involve physical body movement.\\\n",
        "    I am sorting only on how much physical movement this involves,\\\n",
        "    starting with the least movement, and ending with the most movement.\\\n",
        "    I will format the list as a python list of strings. Here is an example.\\\n",
        "    Sort these actions: play soccer, listen to music, pack boxes, order coffee at a cafe.\\\n",
        "    Response: [\"listen to music\", \"order coffee at a cafe\", \"pack boxes\", \"play soccer\"]\\\n",
        "    Sort these actions: {action_string}.'\n",
        "\n",
        "  else:\n",
        "    raise Exception(\"Specify a rating dimension: moral, hedonic, action\")\n",
        "\n",
        "  return prompt\n",
        "\n",
        "def prompt_rate_sorted(action_list, dimension):\n",
        "\n",
        "  #turn list into formatted string\n",
        "  action_string = (', ').join(action_list)\n",
        "\n",
        "  # Switch by rating dimension\n",
        "  if dimension == 'moral':\n",
        "    prompt = f'Given a list of actions, I will rate how similar pairs of actions are in terms of their moral value. \\\n",
        "    I will assign a number to each adjacent pair, rating 0 if the actions are very similar \\\n",
        "    in terms of moral value, and 10 if the actions are very different in terms of moral value. \\\n",
        "    I will give the first action a rating of 0. I will give the second action a rating in comparison to the first action, and so on. \\\n",
        "    I will format the response as a list of python strings, with the action followed by a \":\" and its rating. Here is an example:\\\n",
        "    Rate these actions: rob a bank, steal food, walk a dog, rescue a cat. \\\n",
        "    Response: [\"rob a bank: 0\", \"steal food: 3\", \"walk a dog: 10\", \"rescue a cat: 6\"] \\\n",
        "    Rate these actions: {action_string}.'\n",
        "\n",
        "  elif dimension == 'hedonic':\n",
        "    prompt = f'Given a list of actions, I will rate how similar pairs of actions are in terms of how good or rewarding they are for me. \\\n",
        "    I will assign a number to each adjacent pair, rating 0 if the actions are very similar \\\n",
        "    in terms of being good for me, and 10 if the actions are very different in terms of being good for me. \\\n",
        "    I will give the first action a rating of 0. I will give the second action a rating in comparison to the first action, and so on. \\\n",
        "    I will format the response as a list of python strings, with the action followed by a \":\" and its rating. Here is an example:\\\n",
        "    Rate these actions: lose my wallet, miss the bus, eat a meal, win a sweepstakes. \\\n",
        "    Response: [\"lose my wallet: 0\", \"miss the bus: 2\", \"eat a meal: 9\", \"win a sweepstakes: 8\"]\\\n",
        "    Rate these actions: {action_string}.'\n",
        "\n",
        "  elif dimension == 'action':\n",
        "    prompt = f'Given a list of actions, I will rate how similar pairs of actions are in terms of how much physical movement they involve. \\\n",
        "    I will assign a number to each adjacent pair, rating 0 if the actions are very similar \\\n",
        "    in terms of physical movement, and 10 if the actions are very different in terms of physical movement. \\\n",
        "    I will give the first action a rating of 0. I will give the second action a rating in comparison to the first action, and so on. \\\n",
        "    I will format the response as a list of python strings, with the action followed by a \":\" and its rating. Here is an example:\\\n",
        "    Rate these actions: listen to music, order coffee at a cafe, pack boxes, play soccer. \\\n",
        "    Response: [\"listen to music: 0\", \"order coffee at a cafe: 2\", \"pack boxes: 6\", \"play soccer: 9\"]\\\n",
        "    Rate these actions: {action_string}.'\n",
        "  else:\n",
        "    raise Exception(\"Specify a rating dimension: moral, hedonic, action\")\n",
        "\n",
        "  return prompt"
      ],
      "metadata": {
        "id": "3VzefjcA6SyT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sort and rate function\n",
        "def sort_rate(action_list, sys_prompt, dimension):\n",
        "\n",
        "  resp_sorted = promptGPT2(sys_prompt, prompt_sort(action_list, dimension), 0)\n",
        "\n",
        "  # Converting string to list\n",
        "  try:\n",
        "    resp_sorted = '[' + resp_sorted.split('[')[1]\n",
        "    resp_sorted_list = ast.literal_eval(resp_sorted)\n",
        "  except:\n",
        "    print(resp_sorted)\n",
        "\n",
        "  # define next prompt, which asks GPT to quantify the distances among items\n",
        "  resp_rated = promptGPT2(sys_prompt, prompt_rate_sorted(resp_sorted_list, dimension), 0)\n",
        "\n",
        "  # Convert response to list\n",
        "  try:\n",
        "    resp_rated = '[' + resp_rated.split('[')[1]\n",
        "    resp_rated_list = ast.literal_eval(resp_rated)\n",
        "    resp_rated_list = [r.split(': ') for r in resp_rated_list]\n",
        "  except:\n",
        "    print(resp_rated)\n",
        "\n",
        "\n",
        "  # parse the ratings into a dataframe\n",
        "  resp_df = pd.DataFrame(resp_rated_list, columns=['item', 'rating'])\n",
        "  resp_df['rating'] = pd.to_numeric(resp_df['rating'])\n",
        "  resp_df['rating_sum'] = resp_df['rating'].cumsum()\n",
        "  resp_df['rescored_' + dimension] = resp_df['rating_sum'] / resp_df['rating_sum'].max() * 100\n",
        "  resp_df = resp_df.drop(columns=['rating', 'rating_sum'])\n",
        "\n",
        "  return resp_df"
      ],
      "metadata": {
        "id": "5bOkF4c89Dai"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# process actions\n",
        "def sort_rate_actions(action_list, sys_prompt):\n",
        "\n",
        "  moral_df = sort_rate(action_list, sys_prompt, 'moral')\n",
        "  hedonic_df = sort_rate(action_list, sys_prompt, 'hedonic')\n",
        "  action_df = sort_rate(action_list, sys_prompt, 'action')\n",
        "\n",
        "  full_df = pd.merge(moral_df, hedonic_df, on='item', how='inner')\n",
        "  full_df = pd.merge(full_df, action_df, on='item', how='inner')\n",
        "\n",
        "  return full_df"
      ],
      "metadata": {
        "id": "TBq3sywg9GiD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read in action stimuli and convert to list\n",
        "action_data = pd.read_csv(stim_path+\"action_neurips.csv\",header=None)\n",
        "action_list = action_data[0].tolist()"
      ],
      "metadata": {
        "id": "wDlnc-fs9Jgu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_list = action_list[:18]\n",
        "#new_list = action_list[18:36]\n",
        "#new_list = action_list[36:]"
      ],
      "metadata": {
        "id": "MK8dM8Ef9NEQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sys_prompt = 'I am a diligent human research subject.'"
      ],
      "metadata": {
        "id": "vo3b9rOf9PLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# run the pipeline and get data!\n",
        "full_df = sort_rate_actions(new_list, sys_prompt)"
      ],
      "metadata": {
        "id": "Z6Ub0NXk9RM7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inspect dataframe\n",
        "data_table.DataTable(full_df, include_index=False, num_rows_per_page=20)"
      ],
      "metadata": {
        "id": "nNLNCpo99UEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# correlations\n",
        "full_df.corr()"
      ],
      "metadata": {
        "id": "N5msOjzv9X_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot\n",
        "fig, ax = plt.subplots(figsize=(10, 10))\n",
        "cmap = plt.get_cmap(\"tab20\")\n",
        "\n",
        "plot_i = 1\n",
        "for i in reversed(range(len(full_df))):\n",
        "    x = full_df['rescored_hedonic'].iloc[i]\n",
        "    y = full_df['rescored_moral'].iloc[i]\n",
        "    colors = cmap(i/len(full_df))\n",
        "    l = str(plot_i) + '. ' + full_df['item'].iloc[i].lstrip('[').rstrip(']')\n",
        "    ax.scatter([x],[y], label=l)\n",
        "    ax.annotate(plot_i, (full_df['rescored_hedonic'][i]+2, full_df['rescored_moral'][i]-1))\n",
        "    plot_i += 1\n",
        "\n",
        "ax.set_xlabel('Hedonic')\n",
        "ax.set_ylabel('Moral')\n",
        "ax.legend()"
      ],
      "metadata": {
        "id": "wyYaLTWD9g4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Shift ranking with context"
      ],
      "metadata": {
        "id": "uBwXFXQp6Th_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define prompt_sort_context\n",
        "\n",
        "def prompt_sort_context(action_list, dimension, context):\n",
        "  #context is added to the start of the prompt, action_list as the items to sort\n",
        "\n",
        "  #randomize the order of the list\n",
        "  random.shuffle(action_list)\n",
        "\n",
        "  #turn list into formatted string\n",
        "  action_string = (', ').join(action_list)\n",
        "\n",
        "  # Switch by sorting dimension\n",
        "  if dimension == 'moral':\n",
        "    prompt = f'{context}. \\n I will sort these actions in terms of their moral value.\\\n",
        "    I am sorting only on morality according to how morally wrong each action is,\\\n",
        "    starting with the most morally wrong and ending with the most morally virtuous.\\\n",
        "    I will format the list as a python list of strings. Here is an example.\\\n",
        "    Sort these actions: walk a dog, rob a bank, rescue a cat, steal food. \\\n",
        "    Response: [\"rob a bank\", \"steal food\", \"walk a dog\", \"rescue a cat\"]\\\n",
        "    Sort these actions: {action_string}.'\n",
        "\n",
        "  elif dimension == 'hedonic':\n",
        "    prompt = f'{context}. \\n I will sort these actions in terms of how good and rewarding they are for myself.\\\n",
        "    I am sorting only on how good this action is for me,\\\n",
        "    starting with the most bad and least rewarding, and ending with the most good and rewarding.\\\n",
        "    I will format the list as a python list of strings. Here is an example.\\\n",
        "    Sort these actions: miss the bus, win a sweepstakes, eat a meal, lose my wallet.\\\n",
        "    Response: [\"lose my wallet\", \"miss the bus\", \"eat a meal\", \"win a sweepstakes\"]\\\n",
        "    Sort these actions: {action_string}.'\n",
        "\n",
        "  elif dimension == 'action':\n",
        "    prompt = f'{context}. \\n  I will sort these actions in terms of how much they involve physical body movement.\\\n",
        "    I am sorting only on how much physical movement this involves,\\\n",
        "    starting with the least movement, and ending with the most movement.\\\n",
        "    I will format the list as a python list of strings. Here is an example.\\\n",
        "    Sort these actions: play soccer, listen to music, pack boxes, order coffee at a cafe.\\\n",
        "    Response: [\"listen to music\", \"order coffee at a cafe\", \"pack boxes\", \"play soccer\"]\\\n",
        "    Sort these actions: {action_string}.'\n",
        "\n",
        "  else:\n",
        "    raise Exception(\"Specify a rating dimension: moral, hedonic, action\")\n",
        "\n",
        "  return prompt"
      ],
      "metadata": {
        "id": "AdML8fCV6szx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# read in action stimuli and convert to list\n",
        "action_data = pd.read_csv(stim_path+\"action_neurips.csv\",header=None)\n",
        "action_list = action_data[0].tolist()\n",
        "action_list_1 = action_list[0:18]"
      ],
      "metadata": {
        "id": "C_L-a7tb6xQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def shift_item_with_context(action_list, dimension, key_item, new_context):\n",
        "  '''\n",
        "  Add a new item to the list of actions, identify where it falls along a given dimension.\n",
        "  then change context and see if its position changes.\n",
        "  '''\n",
        "  reps = 10 # n times to repeat the GPT call\n",
        "  no_context = \"I am an average person.\" # Default context\n",
        "\n",
        "  old_index_list = [] # list of index positions with no context\n",
        "  new_index_list = [] # list of positions with new context\n",
        "  action_list.append(key_item) # add the new item we want to measure\n",
        "\n",
        "  for i in range(reps):\n",
        "\n",
        "    # no context\n",
        "    resp_sorted = promptGPT2('I am a diligent human research subject.',\n",
        "                              prompt_sort_context(action_list, dimension, no_context), 0)\n",
        "    try:\n",
        "      resp_sorted = '[' + resp_sorted.split('[')[1]\n",
        "      resp_sorted_list = ast.literal_eval(resp_sorted)\n",
        "      old_index_list.append(resp_sorted_list.index(key_item))\n",
        "    except:\n",
        "      print('GPT crapped out! Response:')\n",
        "      print(resp_sorted)\n",
        "\n",
        "    # new context\n",
        "    resp_sorted = promptGPT2('I am a diligent human research subject.',\n",
        "                              prompt_sort_context(action_list, dimension, new_context), 0)\n",
        "    try:\n",
        "      resp_sorted = '[' + resp_sorted.split('[')[1]\n",
        "      resp_sorted_list = ast.literal_eval(resp_sorted)\n",
        "      new_index_list.append(resp_sorted_list.index(key_item))\n",
        "    except:\n",
        "      print('GPT crapped out! Response:')\n",
        "      print(resp_sorted)\n",
        "\n",
        "  return pd.DataFrame({'old_list': old_index_list, 'new_list': new_index_list})"
      ],
      "metadata": {
        "id": "J2O2rxf47X_U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title test context on moral items\n",
        "key_item = 'eating a hamburger'\n",
        "context = \"I am a vegan, and think it's very wrong to eat meat or consume any product from animals.\"\n",
        "context_df_1 = shift_item_with_context(action_list_1, 'moral', key_item, context)\n",
        "\n",
        "key_item = 'telling a white lie to be polite'\n",
        "context = \"I strongly value honesty and believe it is always wrong to lie.\"\n",
        "context_df_2 = shift_item_with_context(action_list_1, 'moral', key_item, context)\n",
        "\n",
        "key_item = 'swearing in public'\n",
        "context = \"I think it is morally wrong to be impolite and use crass language.\"\n",
        "context_df_3 = shift_item_with_context(action_list_1, 'moral', key_item, context)\n",
        "\n",
        "key_item = 'being nude at the beach'\n",
        "context = \"I am a very modest person and believe that it is wrong to be nude in public.\"\n",
        "context_df_4 = shift_item_with_context(action_list_1, 'moral', key_item, context)\n",
        "\n",
        "key_item = 'driving slowly in the left lane'\n",
        "context = \"I believe that driving so slowly that you impede traffic is very dangerous, immoral, and should be outlawed.\"\n",
        "context_df_5 = shift_item_with_context(action_list_1, 'moral', key_item, context)"
      ],
      "metadata": {
        "id": "4WnWEGNQ7aEL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_df = pd.concat([context_df_1,context_df_2,context_df_3,context_df_4,context_df_5],axis=1)\n",
        "all_df.columns = [\"1 -context\",\"1 +context\",\"2 -context\",\"2 +context\",\"3 -context\",\"3 +context\",\"4 -context\",\"4 +context\",\"5 -context\",\"5 +context\",]"
      ],
      "metadata": {
        "id": "V8bFEbqP7S-q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}